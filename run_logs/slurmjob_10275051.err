
CondaError: Run 'conda init' before 'conda activate'

2025-04-29 09:47:44,538	WARNING deprecation.py:50 -- DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
/next/u/stephhk/miniconda3/envs/orpo/lib/python3.9/site-packages/flow/utils/flow_warnings.py:23: PendingDeprecationWarning: The attribute minGap in SumoCarFollowingParams is deprecated, use min_gap instead.
  warnings.warn(
2025-04-29 09:47:45,840	WARNING algorithm_config.py:2604 -- config._enable_rl_module_api was set to False, but no prior exploration config was found to be restored.
2025-04-29 09:47:45,841	WARNING algorithm_config.py:672 -- Cannot create AlgorithmConfig from given `config_dict`! Property sgd_minibatch_size not supported.
INFO - root - Saving experiment results to pandemic/ORPO/proxy/model_128-128/state/weights_10.0_0.1_0.01/kl-0.06/seed_0
WARNING - orpo_experiments - No observers have been added to this run
INFO - orpo_experiments - Running command 'main'
INFO - orpo_experiments - Started
2025-04-29 09:47:48,077	INFO worker.py:1642 -- Started a local Ray instance.
2025-04-29 09:47:49,463	WARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.
2025-04-29 09:47:49,466	WARNING algorithm_config.py:2592 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.
[2m[36m(pid=1546960)[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=1546960)[0m 2025-04-29 09:47:55,064	WARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.
[2m[36m(RolloutWorker pid=1546960)[0m 2025-04-29 09:47:55,103	WARNING catalog.py:629 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(RolloutWorker pid=1546959)[0m 2025-04-29 09:47:55,079	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
[2m[36m(RolloutWorker pid=1546959)[0m 2025-04-29 09:47:55,079	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=1546960)[0m 'is_safe_policy' key not found in train batch
[2m[36m(RolloutWorker pid=1546960)[0m 'discriminator_rewards' key not found in train batch
[2m[36m(RolloutWorker pid=1546960)[0m 'is_safe_policy' key not found in train batch
[2m[36m(RolloutWorker pid=1546960)[0m 'discriminator_rewards' key not found in train batch
[2m[36m(RolloutWorker pid=1546959)[0m 2025-04-29 09:47:57,283	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=1546959)[0m 2025-04-29 09:47:57,283	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=1546959)[0m 2025-04-29 09:47:57,283	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=1546959)[0m 2025-04-29 09:47:57,283	WARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=1546959)[0m 2025-04-29 09:47:57,288	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
2025-04-29 09:47:57,374	WARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.
2025-04-29 09:47:57,376	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
2025-04-29 09:47:57,376	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
2025-04-29 09:47:57,387	WARNING catalog.py:629 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
2025-04-29 09:47:58,737	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
2025-04-29 09:47:58,737	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
2025-04-29 09:47:58,737	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
2025-04-29 09:47:58,737	WARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!
/next/u/stephhk/miniconda3/envs/orpo/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Could not parse CUBLAS_WORKSPACE_CONFIG, using default workspace size of 8519680 bytes. (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:145.)
  return F.linear(input, self.weight, self.bias)
2025-04-29 09:47:58,808	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
WARNING - occupancy_measures.agents.orpo - 'is_safe_policy' key not found in train batch
WARNING - occupancy_measures.agents.orpo - 'discriminator_rewards' key not found in train batch
2025-04-29 09:47:59,368	WARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.
2025-04-29 09:47:59,373	WARNING catalog.py:629 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
WARNING - occupancy_measures.agents.orpo - 'is_safe_policy' key not found in train batch
WARNING - occupancy_measures.agents.orpo - 'discriminator_rewards' key not found in train batch
2025-04-29 09:47:59,400	WARNING util.py:68 -- Install gputil for GPU system monitoring.
/next/u/stephhk/miniconda3/envs/orpo/lib/python3.9/site-packages/ray/train/_internal/syncer.py:95: UserWarning: `SyncConfig(upload_dir)` is a deprecated configuration and will be ignored. Please remove it from your `SyncConfig`, as this will raise an error in a future version of Ray.
Please specify `train.RunConfig(storage_path)` instead.
  warnings.warn(
/next/u/stephhk/miniconda3/envs/orpo/lib/python3.9/site-packages/ray/train/_internal/syncer.py:95: UserWarning: `SyncConfig(syncer)` is a deprecated configuration and will be ignored. Please remove it from your `SyncConfig`, as this will raise an error in a future version of Ray.
Please implement custom syncing logic with a custom `pyarrow.fs.FileSystem` instead, and pass it into `train.RunConfig(storage_filesystem)`.
  warnings.warn(
INFO - main - loading policy safe_policy0 from data/logs/pandemic/BC/true/model_128-128/seed_0/2025-04-28_09-41-36/checkpoint_000260...
WARNING - occupancy_measures.models.model_with_discriminator - discriminator weights do not match the current discriminator architecture; ignoring discriminator weights
INFO - main - loading policy current from data/logs/pandemic/BC/true/model_128-128/seed_0/2025-04-28_09-41-36/checkpoint_000260...
WARNING - occupancy_measures.models.model_with_discriminator - discriminator weights do not match the current discriminator architecture; ignoring discriminator weights
INFO - main - Starting training iteration 0
[2m[36m(RolloutWorker pid=1546960)[0m discriminator weights do not match the current discriminator architecture; ignoring discriminator weights
[2m[36m(RolloutWorker pid=1546960)[0m discriminator weights do not match the current discriminator architecture; ignoring discriminator weights
[2m[36m(pid=1546959)[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
slurmstepd: error: *** JOB 10275051 ON next5 CANCELLED AT 2025-04-29T09:50:37 ***
